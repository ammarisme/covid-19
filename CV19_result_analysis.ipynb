{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "CV19-result-analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ammarisme/covid-19/blob/master/CV19_result_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anKz91FjrQn3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "!pip install torch-geometric \\\n",
        "  torch-sparse==latest+cu101 \\\n",
        "  torch-scatter==latest+cu101 \\\n",
        "  torch-cluster==latest+cu101 \\\n",
        "  -f https://pytorch-geometric.com/whl/torch-1.5.0.html"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYMKVm0cWK57",
        "colab_type": "code",
        "outputId": "8a44de6a-e646-400d-f6a6-d935c20aa57b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "from functools import reduce\n",
        "import os\n",
        "\n",
        "import torch\n",
        "from torch_geometric.data import Data, DataLoader, InMemoryDataset\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('running on '+ (\"GPU\" if torch.cuda.is_available() else \"CPU\"))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running on CPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFsXKb1CzwSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "PATH = '/content/drive/My Drive/covid'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3KymLSjN91m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_file_search(mypath):\n",
        "  losses_files = [f for f in listdir(mypath) if (\"losses\" in f)]\n",
        "  ax_paths = []\n",
        "  for loss_file in losses_files:\n",
        "    losses = np.load(join(mypath, loss_file), allow_pickle=True)\n",
        "    training_loss = np.array(losses.tolist()['losses']).T[0]\n",
        "    ax = plt.plot(training_loss)\n",
        "    filepath = mypath\n",
        "    ax_paths.append((ax, filepath))\n",
        "  \n",
        "  directories = [f for f in listdir(mypath) if os.path.isdir(join(mypath, f))]\n",
        "  for directory in directories:\n",
        "    ax_paths.append(loss_file_search(mypath+'/'+directory))\n",
        "  \n",
        "  return ax_paths\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlSW4je3USF9",
        "colab_type": "code",
        "outputId": "ec72b674-78e4-41e4-da6f-c0c76aee6f77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import ylim\n",
        "\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "\n",
        "root = PATH+'/models__rnn/4'\n",
        "#ylim(top=5.08, bottom=5.07)#, ylim_bottom=5.0\n",
        "#ax_paths = loss_file_search(root)\n",
        "\"\"\"axes = [ax_path[0][0] for ax_path in ax_paths]\n",
        "paths = [ax_path[0][1][-1] for ax_path in ax_paths]\n",
        "colors = {\n",
        "    0 :\"red\",\n",
        "    3 : \"green\",\n",
        "    4 : \"blue\",\n",
        "    6: \"orange\"\n",
        "}\n",
        "plt.legend(handles=[\n",
        "                    mpatches.Patch(color=colors[int(path)], label=str(path)) for path in paths])\n",
        "plt.show()\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'axes = [ax_path[0][0] for ax_path in ax_paths]\\npaths = [ax_path[0][1][-1] for ax_path in ax_paths]\\ncolors = {\\n    0 :\"red\",\\n    3 : \"green\",\\n    4 : \"blue\",\\n    6: \"orange\"\\n}\\nplt.legend(handles=[\\n                    mpatches.Patch(color=colors[int(path)], label=str(path)) for path in paths])\\nplt.show()\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKX_tm-MVOv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CovidDataSet(InMemoryDataset):\n",
        "    def __init__(self, root, input_sequence, output_sequence, transform=None, pre_transform=None):\n",
        "        super(CovidDataSet, self).__init__(root, transform, pre_transform)\n",
        "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
        "\n",
        "    @property\n",
        "    def raw_dir(self):\n",
        "      if os.path.exists(self.root+PROCESSED_DIR):\n",
        "        return self.root+'/cleaned'\n",
        "      else:\n",
        "        os.mkdir(self.root+PROCESSED_DIR)\n",
        "        return self.root+'/cleaned'\n",
        "        \n",
        "    @property\n",
        "    def processed_dir(self):\n",
        "      if os.path.exists(self.root+PROCESSED_DIR):\n",
        "        return self.root+PROCESSED_DIR\n",
        "      else:\n",
        "        os.mkdir(self.root+PROCESSED_DIR)\n",
        "        return self.root+PROCESSED_DIR\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "      mypath = self.raw_dir\n",
        "      filenames = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
        "      return filenames\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return ['processed.dt']\n",
        "\n",
        "    def download(self):\n",
        "        pass\n",
        "    \n",
        "    def process(self):\n",
        "        \n",
        "        data_list = []\n",
        "\n",
        "        for raw_path in self.raw_paths:\n",
        "          df = pd.read_csv(raw_path)\n",
        "          for synthetic_seq in df['synthesis_seq'].unique():\n",
        "            synthetic_data = df[df['synthesis_seq']==synthetic_seq]\n",
        "\n",
        "            for country in synthetic_data['countryterritoryCode'].unique():\n",
        "              country_data = synthetic_data[synthetic_data['countryterritoryCode'] == country]\n",
        "              popData2018 = country_data['popData2018'].values[0]\n",
        "              _country_code = country_data['_country_code'].values[0]\n",
        "              \n",
        "              country_data_i = country_data[:-configuration['output_sequence_len']]\n",
        "              country_data_o = country_data[configuration['input_sequence_len']:]\n",
        "              \n",
        "              \n",
        "              country_data_array = np.array([country_data_i['cases'].to_numpy(),\n",
        "                                             country_data_i['deaths'].to_numpy()\n",
        "                                             ])\n",
        "              \"\"\"\n",
        "              country_data_i['_country_code'].to_numpy(),\n",
        "                                             country_data_i['countriesAndTerritories'].to_numpy(),\n",
        "                                             country_data_i['geoId'].to_numpy(),\n",
        "                                             country_data_i['countryterritoryCode'].to_numpy(),\n",
        "                                             country_data_i['continentExp'].to_numpy()\n",
        "              \"\"\"\n",
        "              feature_length = len(country_data_array)\n",
        "              country_data_array = country_data_array.reshape(feature_length,len(country_data_i))\n",
        "\n",
        "              country_data_array_y = np.array([country_data_o['cases'].to_numpy(), country_data_o['deaths'].to_numpy()])\n",
        "              country_data_array_y = country_data_array_y.reshape(2,len(country_data_o))\n",
        "\n",
        "              x = country_data_array[:feature_length].T\n",
        "              y = country_data_array_y[:2].T\n",
        "\n",
        "              sets =0\n",
        "              x_list = []\n",
        "              dict_x = dict()\n",
        "              for i in range(configuration['input_sequence_len']):\n",
        "                array_len = ((len(x) -i) - ((len(x)-i)%configuration['input_sequence_len']))+i\n",
        "                if array_len <= 0:\n",
        "                  continue\n",
        "                sets = int( array_len/ configuration['input_sequence_len'])\n",
        "                if sets <= 0:\n",
        "                  continue\n",
        "                #print('input seq : ', i , ' ', array_len , ' ',array_len-i , ' number of sets : ', sets)\n",
        "                x_temp = x[i:array_len].T.reshape(sets,feature_length,configuration['input_sequence_len'])\n",
        "                x_temp = x_temp.reshape(feature_length,sets,configuration['input_sequence_len'])\n",
        "                uniq_keys = np.array([i+(configuration['input_sequence_len']*k) for k in range(configuration['input_sequence_len'])])\n",
        "                \n",
        "                arrays_split = np.hsplit(x_temp,sets)\n",
        "                dict_x.update(dict(zip(uniq_keys, arrays_split)))\n",
        "              \n",
        "              dict_y = dict()\n",
        "              y_list = []\n",
        "              for i in range(configuration['output_sequence_len']):\n",
        "                array_len_y = (len(y)-i) - ((len(y)  - i)%configuration['output_sequence_len'])+i\n",
        "                if array_len_y <= 0:\n",
        "                  continue\n",
        "                sets = int(array_len_y / configuration['output_sequence_len'])\n",
        "                if sets <= 0:\n",
        "                  continue\n",
        "                \n",
        "                #print('output seq : ', i , ' ', array_len_y , ' ',array_len_y-(i) , ' number of sets : ', sets)\n",
        "                y_temp = y[i:array_len_y].T.reshape(sets, 2, configuration['output_sequence_len'])\n",
        "                uniq_keys = np.array([i+(configuration['output_sequence_len']*k) for k in range(configuration['output_sequence_len'])])\n",
        "                y_temp = y_temp.reshape(2,sets,configuration['output_sequence_len'])\n",
        "                arrays_split = np.hsplit(y_temp,sets)\n",
        "                dict_y.update(dict(zip(uniq_keys, arrays_split)))\n",
        "              \n",
        "\n",
        "              temp_x_list  = [dict_x[i].T for i in sorted(dict_x.keys())]\n",
        "              temp_y_list  = [dict_y[i].T for i in sorted(dict_y.keys())]\n",
        "\n",
        "              #_country_code,popData2018\n",
        "              xy_list = [Data(x = torch.from_numpy(features).type(torch.FloatTensor).squeeze()) for features in temp_x_list]\n",
        "\n",
        "              for i in sorted(dict_y.keys()):\n",
        "                xy_list[i].y = torch.from_numpy(temp_y_list[i]).squeeze()\n",
        "\n",
        "              data_list += xy_list\n",
        "          print('processed : '+ raw_path)\n",
        "        data, slices = self.collate(data_list)\n",
        "        torch.save((data, slices), self.processed_paths[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkZyInZqYdRa",
        "colab_type": "code",
        "outputId": "d3e2aba2-8ad6-42bc-9bd4-2a6851db0b01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "configuration = {\n",
        "    'input_sequence_len' : 10,\n",
        "    'output_sequence_len' : 10,\n",
        "    'training_batch_size' : 1024,\n",
        "    'training_dataset_length' :32768,\n",
        "    'validation_batch_size' : 1024,\n",
        "    'yhat_size' : 2,\n",
        "    'feature_len' : 2,\n",
        "    'output_size' : 2,\n",
        "}\n",
        "\n",
        "\n",
        "INPUT_ROOT = PATH+'/input_test'\n",
        "DATA_TAG = \"seq2seq_\"+str(configuration['input_sequence_len'])+'_'+str(configuration['output_sequence_len'])\n",
        "PROCESSED_DIR = '/processed_'+DATA_TAG\n",
        "\n",
        "validation_dataset = CovidDataSet(INPUT_ROOT, configuration['input_sequence_len'], configuration['output_sequence_len'])\n",
        "validation_dataset = validation_dataset.shuffle()\n",
        "validation_dataset = validation_dataset[3000:]\n",
        "validation_dataloader = DataLoader(validation_dataset,batch_size=configuration['validation_batch_size'])\n",
        "\n",
        "print('batches validation :', len(validation_dataloader))\n",
        "print('dataset length validation :', len(validation_dataset))\n",
        "print('sample data :', validation_dataset[100].x)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing...\n",
            "processed : /content/drive/My Drive/covid/input_test/cleaned/Copy of cleaned_worldwide_cases_27_04.csv\n",
            "Done!\n",
            "batches validation : 7\n",
            "dataset length validation : 6260\n",
            "sample data : tensor([[ 0.,  0.],\n",
            "        [ 0.,  0.],\n",
            "        [18.,  0.],\n",
            "        [ 0.,  0.],\n",
            "        [ 9.,  0.],\n",
            "        [ 2.,  0.],\n",
            "        [10.,  0.],\n",
            "        [ 0.,  0.],\n",
            "        [ 1.,  0.],\n",
            "        [ 4.,  0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUrnl4KvhkWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, input_size, parameter_sizes, repeats ,output_size):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.repeater_input_size = parameter_sizes[0]\n",
        "        self.hidden_size = parameter_sizes[1]\n",
        "        self.repeats = repeats\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.fc1 = nn.Linear(input_size, self.repeater_input_size)\n",
        "        self.relu_activation = nn.ReLU()\n",
        "\n",
        "        self.layers = dict()\n",
        "\n",
        "        \n",
        "        k = 0\n",
        "        for i in range(repeats):\n",
        "          i = i+k\n",
        "          self.layers['fc_'+str(i)] = nn.Linear(self.repeater_input_size, self.hidden_size)\n",
        "          self.layers['gru_'+str(i+1)] = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "          self.layers['fc_'+str(i+2)] = nn.Linear(self.hidden_size, self.repeater_input_size)\n",
        "          k+=2\n",
        "\n",
        "        self.module_list = nn.ModuleDict(self.layers)\n",
        "\n",
        "        self.fc2 = nn.Linear(self.repeater_input_size, output_size)\n",
        "        \n",
        "    def forward(self, input, hidden):\n",
        "      output = self.fc1(input)\n",
        "      output = self.relu_activation(output)\n",
        "      k = 0\n",
        "      for i in range(self.repeats):\n",
        "        i = i+k\n",
        "        output = self.layers['fc_'+str(i)](output)\n",
        "        output = self.relu_activation(output)\n",
        "\n",
        "        output, hidden[i-k] = self.layers['gru_'+str(i+1)](output, hidden[i-k])#should be different. check the nlp page\n",
        "        output = self.relu_activation(output)\n",
        "        hidden[i-k] = self.relu_activation(hidden[i-k])\n",
        "\n",
        "        output = self.layers['fc_'+str(i+2)](output)\n",
        "        output = self.relu_activation(output)\n",
        "        k +=2\n",
        "\n",
        "      output = self.fc2(output)\n",
        "      output = self.relu_activation(output)\n",
        "\n",
        "      return output, hidden\n",
        "\n",
        "    def initHidden(self, batch_size):\n",
        "        return torch.zeros(1, batch_size, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Je__Iq5Khp9P",
        "colab_type": "code",
        "outputId": "b500fd1b-cb77-4392-feb8-5cfd7f7337be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def predict(input_tensor, rnn_model):\n",
        "  with torch.no_grad():\n",
        "    input_tensor = input_tensor.type(torch.FloatTensor)\n",
        "\n",
        "    rnn_model_hidden = []\n",
        "    for i in range(5):\n",
        "      rnn_model_hidden.append(rnn_model.initHidden(1))\n",
        "\n",
        "    validation_loss = 0\n",
        "    \n",
        "    outputs = []\n",
        "\n",
        "    for ei in range(configuration['input_sequence_len']):\n",
        "      input_tensor_seq = input_tensor.view(configuration['input_sequence_len'],1, configuration['feature_len'])[ei]\n",
        "      \n",
        "      input_tensor_seq = input_tensor_seq.view(1, 1, configuration['feature_len']).to(device)\n",
        "      rnn_model_output, rnn_model_hidden = rnn_model(\n",
        "          input_tensor_seq, rnn_model_hidden)\n",
        "      outputs.append(rnn_model_output.detach().numpy())\n",
        "\n",
        "  return outputs\n",
        "model = RNNModel(**{\n",
        "         'input_size': 2,\n",
        "         'parameter_sizes': [256, 128] ,\n",
        "         'repeats' : 5 ,\n",
        "         'output_size': 2\n",
        "         })\n",
        "\n",
        "model.eval()\n",
        "for i in range(1000):\n",
        "  out1 = np.array(predict(torch.tensor(validation_dataset[100].x), model)).squeeze()\n",
        "  out2 = np.array(predict(torch.tensor(validation_dataset[100].x), model)).squeeze()\n",
        "  if np.sum(out1 - out2)==0:\n",
        "    print('Model is broken', np.sum(out1) , np.sum(out2))\n",
        "  #else:\n",
        "  #  print('Model is fine', np.sum(out1) , np.sum(out2))"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n",
            "Model is broken 0.8425294 0.8425294\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-99-b0c2034147bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m   \u001b[0mout1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m   \u001b[0mout2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mout2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-99-b0c2034147bb>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(input_tensor, rnn_model)\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0minput_tensor_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_tensor_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfiguration\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feature_len'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       rnn_model_output, rnn_model_hidden = rnn_model(\n\u001b[0;32m---> 18\u001b[0;31m           input_tensor_seq, rnn_model_hidden)\n\u001b[0m\u001b[1;32m     19\u001b[0m       \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_model_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-79-52e609d126f4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gru_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#should be different. check the nlp page\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_activation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_activation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fc_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNmtkfNkk5xx",
        "colab_type": "code",
        "outputId": "94f8e4bc-fa73-465f-eb56-9ec3bfc4af44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "print('weights',np.mean(model.fc1.weight.detach().numpy()))\n",
        "print('bias',np.mean(model.fc1.bias.detach().numpy()))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights 0.016845142\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-affcffa869f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weights'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bias'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'detach'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy536wg3Yxgs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = RNNModel(**{\n",
        "         'input_size': 2,\n",
        "         'parameter_sizes': [256, 128] ,\n",
        "         'repeats' : 5 ,\n",
        "         'output_size': 2\n",
        "         })\n",
        "#model_statedict = torch.load(root+'/model_manual_save_0628_5.pt', map_location=torch.device('cpu'))\n",
        "#model.load_state_dict(model_statedict)\n",
        "#model.train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXvYVErxejcj",
        "colab_type": "code",
        "outputId": "baf2dbf3-f4fe-431a-d8bf-11cc4f3bb403",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "out1 = np.array(predict(torch.tensor(validation_dataset[100].x), model)).squeeze()\n",
        "out2 = np.array(predict(torch.tensor(validation_dataset[101].x), model)).squeeze()\n",
        "if np.sum(out1 - out2)==0: print('Model is broken')"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83UftElCxi27",
        "colab_type": "code",
        "outputId": "c2a641ea-3718-411a-8d5e-d7f65cfaab55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "def get_all_directories(mypath):  \n",
        "  directories= [f for f in listdir('/'+mypath) if os.path.isdir(join(mypath, f))]\n",
        "  for directory in directories:\n",
        "    get_all_directories(directory)\n",
        "    #loss_file_search(mypath+'/'+directory)\n",
        "\n",
        "get_all_directories(PATH)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-135-8efde3e24b20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#loss_file_search(mypath+'/'+directory)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mget_all_directories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-135-8efde3e24b20>\u001b[0m in \u001b[0;36mget_all_directories\u001b[0;34m(mypath)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mdirectories\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmypath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmypath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdirectories\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mget_all_directories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m#loss_file_search(mypath+'/'+directory)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-135-8efde3e24b20>\u001b[0m in \u001b[0;36mget_all_directories\u001b[0;34m(mypath)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_all_directories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmypath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mdirectories\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmypath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmypath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdirectories\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mget_all_directories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#loss_file_search(mypath+'/'+directory)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/input'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHfsG7LGx5bD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtNJT5sQRI7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_analysis(losses):\n",
        " print('loss analysis') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-bCsXyXOOdg",
        "colab_type": "code",
        "outputId": "56b07f0d-aa61-4ba8-f0a3-07a240f8d4aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CV19 Cleaning.ipynb',\n",
              " 'CV19_Synthesis.ipynb',\n",
              " '_Common.ipynb',\n",
              " 'common (1).py',\n",
              " 'common.py',\n",
              " 'CV19Net.ipynb',\n",
              " 'rnn_model_configurations_1001_443838.csv',\n",
              " 'rnn_model_configurations_1001_165567.csv',\n",
              " 'rnn_model_configurations_1001_353166.csv',\n",
              " 'rnn_model_configurations_1001_57460.csv',\n",
              " 'rnn_model_configurations_1001_981028.csv',\n",
              " 'CV19 Dataset Explore.ipynb',\n",
              " 'CV19_Dataset.ipynb',\n",
              " 'RNN-CV19Net.ipynb',\n",
              " 'CV19-result-analysis.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wq7W28W7Pv4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}