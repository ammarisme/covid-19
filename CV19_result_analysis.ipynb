{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "CV19-result-analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ammarisme/covid-19/blob/master/CV19_result_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anKz91FjrQn3",
        "colab_type": "code",
        "outputId": "b3705112-62e1-4b54-9bb0-5fae9f2816a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%matplotlib inline\n",
        "!pip install torch-geometric \\\n",
        "  torch-sparse==latest+cu101 \\\n",
        "  torch-scatter==latest+cu101 \\\n",
        "  torch-cluster==latest+cu101 \\\n",
        "  -f https://pytorch-geometric.com/whl/torch-1.5.0.html"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
            "Collecting torch-geometric\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/35/8a65fc0b685d916f5f70199d6ad6f19bb002dc3a547a3fe5b68d60047f3b/torch_geometric-1.4.3.tar.gz (129kB)\n",
            "\r\u001b[K     |██▌                             | 10kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████                           | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 40kB 1.6MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 71kB 2.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 81kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 2.7MB/s \n",
            "\u001b[?25hCollecting torch-sparse==latest+cu101\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.5.0/torch_sparse-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (21.9MB)\n",
            "\u001b[K     |████████████████████████████████| 21.9MB 1.4MB/s \n",
            "\u001b[?25hCollecting torch-scatter==latest+cu101\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.5.0/torch_scatter-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (12.2MB)\n",
            "\u001b[K     |████████████████████████████████| 12.3MB 53.6MB/s \n",
            "\u001b[?25hCollecting torch-cluster==latest+cu101\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.5.0/torch_cluster-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (18.2MB)\n",
            "\u001b[K     |████████████████████████████████| 18.2MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.5.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.22.2.post1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.16.2)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.48.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.23.0)\n",
            "Collecting plyfile\n",
            "  Downloading https://files.pythonhosted.org/packages/93/c8/cf47848cd4d661850e4a8e7f0fc4f7298515e06d0da7255ed08e5312d4aa/plyfile-0.7.2-py3-none-any.whl\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.0.3)\n",
            "Collecting rdflib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/6b/6454aa1db753c0f8bc265a5bd5c10b5721a4bb24160fb4faf758cf6be8a1/rdflib-5.0.0-py3-none-any.whl (231kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.10.0)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torch-geometric) (0.16.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->torch-geometric) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->torch-geometric) (0.14.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->torch-geometric) (3.2.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->torch-geometric) (1.1.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->torch-geometric) (7.0.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->torch-geometric) (2.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba->torch-geometric) (46.1.3)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba->torch-geometric) (0.31.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Collecting isodate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (1.12.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->torch-geometric) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->torch-geometric) (0.10.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-1.4.3-cp36-none-any.whl size=234873 sha256=e8620c481d785919f634c36ad9ccfa2d744995a0e4d9dda66c01206dd7d07639\n",
            "  Stored in directory: /root/.cache/pip/wheels/e2/c1/09/8693feee3f97e440d68b09abfca8b4c1e97150ace350b5003f\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: plyfile, isodate, rdflib, torch-geometric, torch-sparse, torch-scatter, torch-cluster\n",
            "Successfully installed isodate-0.6.0 plyfile-0.7.2 rdflib-5.0.0 torch-cluster-1.5.4 torch-geometric-1.4.3 torch-scatter-2.0.4 torch-sparse-0.6.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYMKVm0cWK57",
        "colab_type": "code",
        "outputId": "871ddd98-8fbb-46de-ff9b-6e5378682273",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "from functools import reduce\n",
        "import os\n",
        "\n",
        "import torch\n",
        "from torch_geometric.data import Data, DataLoader, InMemoryDataset\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('running on '+ (\"GPU\" if torch.cuda.is_available() else \"CPU\"))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running on CPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFsXKb1CzwSY",
        "colab_type": "code",
        "outputId": "962ba2d9-84ea-4905-b877-943abaa2b434",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "PATH = '/content/drive/My Drive/covid'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3KymLSjN91m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_file_search(mypath):\n",
        "  losses_files = [f for f in listdir(mypath) if (\"losses\" in f)]\n",
        "  ax_paths = []\n",
        "  for loss_file in losses_files:\n",
        "    losses = np.load(join(mypath, loss_file), allow_pickle=True)\n",
        "    training_loss = np.array(losses.tolist()['losses']).T[0]\n",
        "    ax = plt.plot(training_loss)\n",
        "    filepath = mypath\n",
        "    ax_paths.append((ax, filepath))\n",
        "  \n",
        "  directories = [f for f in listdir(mypath) if os.path.isdir(join(mypath, f))]\n",
        "  for directory in directories:\n",
        "    ax_paths.append(loss_file_search(mypath+'/'+directory))\n",
        "  \n",
        "  return ax_paths\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlSW4je3USF9",
        "colab_type": "code",
        "outputId": "ec72b674-78e4-41e4-da6f-c0c76aee6f77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import ylim\n",
        "\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "\n",
        "root = PATH+'/models__rnn/4'\n",
        "#ylim(top=5.08, bottom=5.07)#, ylim_bottom=5.0\n",
        "#ax_paths = loss_file_search(root)\n",
        "\"\"\"axes = [ax_path[0][0] for ax_path in ax_paths]\n",
        "paths = [ax_path[0][1][-1] for ax_path in ax_paths]\n",
        "colors = {\n",
        "    0 :\"red\",\n",
        "    3 : \"green\",\n",
        "    4 : \"blue\",\n",
        "    6: \"orange\"\n",
        "}\n",
        "plt.legend(handles=[\n",
        "                    mpatches.Patch(color=colors[int(path)], label=str(path)) for path in paths])\n",
        "plt.show()\n",
        "\"\"\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'axes = [ax_path[0][0] for ax_path in ax_paths]\\npaths = [ax_path[0][1][-1] for ax_path in ax_paths]\\ncolors = {\\n    0 :\"red\",\\n    3 : \"green\",\\n    4 : \"blue\",\\n    6: \"orange\"\\n}\\nplt.legend(handles=[\\n                    mpatches.Patch(color=colors[int(path)], label=str(path)) for path in paths])\\nplt.show()\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKX_tm-MVOv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CovidDataSet(InMemoryDataset):\n",
        "    def __init__(self, root, input_sequence, output_sequence, transform=None, pre_transform=None):\n",
        "        super(CovidDataSet, self).__init__(root, transform, pre_transform)\n",
        "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
        "\n",
        "    @property\n",
        "    def raw_dir(self):\n",
        "      if os.path.exists(self.root+PROCESSED_DIR):\n",
        "        return self.root+'/cleaned'\n",
        "      else:\n",
        "        os.mkdir(self.root+PROCESSED_DIR)\n",
        "        return self.root+'/cleaned'\n",
        "        \n",
        "    @property\n",
        "    def processed_dir(self):\n",
        "      if os.path.exists(self.root+PROCESSED_DIR):\n",
        "        return self.root+PROCESSED_DIR\n",
        "      else:\n",
        "        os.mkdir(self.root+PROCESSED_DIR)\n",
        "        return self.root+PROCESSED_DIR\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "      mypath = self.raw_dir\n",
        "      filenames = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
        "      return filenames\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return ['processed.dt']\n",
        "\n",
        "    def download(self):\n",
        "        pass\n",
        "    \n",
        "    def process(self):\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkZyInZqYdRa",
        "colab_type": "code",
        "outputId": "373624e3-bf5b-40be-e14b-a034ef74617a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "configuration = {\n",
        "    'input_sequence_len' : 10,\n",
        "    'output_sequence_len' : 10,\n",
        "    'training_batch_size' : 1024,\n",
        "    'training_dataset_length' :32768,\n",
        "    'validation_batch_size' : 1024,\n",
        "    'yhat_size' : 2,\n",
        "    'feature_len' : 8,\n",
        "    'output_size' : 2,\n",
        "}\n",
        "\n",
        "\n",
        "INPUT_ROOT = PATH+'/input_mix'\n",
        "DATA_TAG = \"seq2seq_\"+str(configuration['input_sequence_len'])+'_'+str(configuration['output_sequence_len'])\n",
        "PROCESSED_DIR = '/processed_'+DATA_TAG\n",
        "\n",
        "validation_dataset = CovidDataSet(INPUT_ROOT+'/validation', configuration['input_sequence_len'], configuration['output_sequence_len'])\n",
        "validation_dataset = validation_dataset.shuffle()\n",
        "validation_dataset = validation_dataset[3000:]\n",
        "validation_dataloader = DataLoader(validation_dataset,batch_size=configuration['validation_batch_size'])\n",
        "\n",
        "print('batches validation :', len(validation_dataloader))\n",
        "print('dataset length validation :', len(validation_dataset))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batches validation : 7\n",
            "dataset length validation : 6260\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUrnl4KvhkWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, input_size, parameter_sizes, repeats ,output_size):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.repeater_input_size = parameter_sizes[0]\n",
        "        self.hidden_size = parameter_sizes[1]\n",
        "        self.repeats = repeats\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.fc1 = nn.Linear(input_size, self.repeater_input_size)\n",
        "        self.relu_activation = nn.ReLU()\n",
        "\n",
        "        self.layers = dict()\n",
        "\n",
        "        \n",
        "        k = 0\n",
        "        for i in range(repeats):\n",
        "          i = i+k\n",
        "          self.layers['fc_'+str(i)] = nn.Linear(self.repeater_input_size, self.hidden_size)\n",
        "          self.layers['gru_'+str(i+1)] = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "          self.layers['fc_'+str(i+2)] = nn.Linear(self.hidden_size, self.repeater_input_size)\n",
        "          k+=2\n",
        "\n",
        "        self.module_list = nn.ModuleDict(self.layers)\n",
        "\n",
        "        self.fc2 = nn.Linear(self.repeater_input_size, output_size)\n",
        "        \n",
        "    def forward(self, input, hidden):\n",
        "      output = self.fc1(input)\n",
        "      output = self.relu_activation(output)\n",
        "      print(output.sum())\n",
        "      k = 0\n",
        "      for i in range(self.repeats):\n",
        "        i = i+k\n",
        "        output = self.layers['fc_'+str(i)](output)\n",
        "        output = self.relu_activation(output)\n",
        "\n",
        "        output, hidden[i-k] = self.layers['gru_'+str(i+1)](output, hidden[i-k])#should be different. check the nlp page\n",
        "        output = self.relu_activation(output)\n",
        "        hidden[i-k] = self.relu_activation(hidden[i-k])\n",
        "\n",
        "        output = self.layers['fc_'+str(i+2)](output)\n",
        "        output = self.relu_activation(output)\n",
        "        k +=2\n",
        "\n",
        "      output = self.fc2(output)\n",
        "      output = self.relu_activation(output)\n",
        "\n",
        "      return output, hidden\n",
        "\n",
        "    def initHidden(self, batch_size):\n",
        "        return torch.zeros(1, batch_size, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Je__Iq5Khp9P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "995391ee-ab04-441a-dabb-562b06e03102"
      },
      "source": [
        "def predict(input_tensor, rnn_model):\n",
        "  with torch.no_grad():\n",
        "    input_tensor = input_tensor.type(torch.FloatTensor)\n",
        "\n",
        "    rnn_model_hidden = []\n",
        "    for i in range(5):\n",
        "      rnn_model_hidden.append(rnn_model.initHidden(1))\n",
        "\n",
        "    validation_loss = 0\n",
        "    \n",
        "    outputs = []\n",
        "\n",
        "    for ei in range(configuration['input_sequence_len']):\n",
        "      input_tensor_seq = input_tensor.view(configuration['input_sequence_len'],1, configuration['feature_len'])[ei]\n",
        "      \n",
        "      input_tensor_seq = input_tensor_seq.view(1, 1, configuration['feature_len']).to(device)\n",
        "      rnn_model_output, rnn_model_hidden = rnn_model(\n",
        "          input_tensor_seq, rnn_model_hidden)\n",
        "      outputs.append(rnn_model_output.detach().numpy())\n",
        "\n",
        "  return outputs\n",
        "model = RNNModel(**{\n",
        "         'input_size': 8,\n",
        "         'parameter_sizes': [256, 128] ,\n",
        "         'repeats' : 5 ,\n",
        "         'output_size': 2\n",
        "         })\n",
        "\n",
        "model.eval()\n",
        "out1 = np.array(predict(torch.tensor(validation_dataset[50].x), model)).squeeze()\n",
        "#out2 = np.array(predict(torch.tensor(validation_dataset[100].x), model)).squeeze()\n",
        "#if np.sum(out1 - out2)==0: print('Model is broken')"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.6286e+08)\n",
            "tensor(2.6286e+08)\n",
            "tensor(2.6286e+08)\n",
            "tensor(2.6286e+08)\n",
            "tensor(2.6286e+08)\n",
            "tensor(2.6286e+08)\n",
            "tensor(2.6286e+08)\n",
            "tensor(2.6286e+08)\n",
            "tensor(2.6286e+08)\n",
            "tensor(2.6286e+08)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNmtkfNkk5xx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9533892f-705f-4b72-a1f8-5c298394fb92"
      },
      "source": [
        "print('weights',np.mean(model.fc1.weight.detach().numpy()))\n",
        "print('bias',np.mean(model.fc1.bias.detach().numpy()))"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights 0.0003171371\n",
            "bias -0.0071668727\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy536wg3Yxgs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = RNNModel(**{\n",
        "         'input_size': 8,\n",
        "         'parameter_sizes': [256, 128] ,\n",
        "         'repeats' : 5 ,\n",
        "         'output_size': 2\n",
        "         })\n",
        "#model_statedict = torch.load(root+'/model_manual_save_0628_5.pt', map_location=torch.device('cpu'))\n",
        "#model.load_state_dict(model_statedict)\n",
        "#model.train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXvYVErxejcj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "b7e4b865-3e43-4351-dbed-fa1e7ea0ce0c"
      },
      "source": [
        "out1 = np.array(predict(torch.tensor(validation_dataset[50].x), model)).squeeze()\n",
        "out2 = np.array(predict(torch.tensor(validation_dataset[100].x), model)).squeeze()\n",
        "if np.sum(out1 - out2)==0: print('Model is broken')"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model is broken\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83UftElCxi27",
        "colab_type": "code",
        "outputId": "c2a641ea-3718-411a-8d5e-d7f65cfaab55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "def get_all_directories(mypath):  \n",
        "  directories= [f for f in listdir('/'+mypath) if os.path.isdir(join(mypath, f))]\n",
        "  for directory in directories:\n",
        "    get_all_directories(directory)\n",
        "    #loss_file_search(mypath+'/'+directory)\n",
        "\n",
        "get_all_directories(PATH)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-135-8efde3e24b20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#loss_file_search(mypath+'/'+directory)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mget_all_directories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-135-8efde3e24b20>\u001b[0m in \u001b[0;36mget_all_directories\u001b[0;34m(mypath)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mdirectories\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmypath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmypath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdirectories\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mget_all_directories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m#loss_file_search(mypath+'/'+directory)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-135-8efde3e24b20>\u001b[0m in \u001b[0;36mget_all_directories\u001b[0;34m(mypath)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_all_directories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmypath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mdirectories\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmypath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmypath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdirectories\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mget_all_directories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#loss_file_search(mypath+'/'+directory)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/input'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHfsG7LGx5bD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtNJT5sQRI7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_analysis(losses):\n",
        " print('loss analysis') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-bCsXyXOOdg",
        "colab_type": "code",
        "outputId": "56b07f0d-aa61-4ba8-f0a3-07a240f8d4aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CV19 Cleaning.ipynb',\n",
              " 'CV19_Synthesis.ipynb',\n",
              " '_Common.ipynb',\n",
              " 'common (1).py',\n",
              " 'common.py',\n",
              " 'CV19Net.ipynb',\n",
              " 'rnn_model_configurations_1001_443838.csv',\n",
              " 'rnn_model_configurations_1001_165567.csv',\n",
              " 'rnn_model_configurations_1001_353166.csv',\n",
              " 'rnn_model_configurations_1001_57460.csv',\n",
              " 'rnn_model_configurations_1001_981028.csv',\n",
              " 'CV19 Dataset Explore.ipynb',\n",
              " 'CV19_Dataset.ipynb',\n",
              " 'RNN-CV19Net.ipynb',\n",
              " 'CV19-result-analysis.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wq7W28W7Pv4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}