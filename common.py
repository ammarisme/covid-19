# -*- coding: utf-8 -*-
"""Common.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xmH26k3q_dH9bJ6bvCPwjm_BntmgVPSH
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
!pip install torch-geometric \
  torch-sparse==latest+cu101 \
  torch-scatter==latest+cu101 \
  torch-cluster==latest+cu101 \
  -f https://pytorch-geometric.com/whl/torch-1.5.0.html

"""!pip install torch-geometric \
  torch-sparse==latest+cu101 \
  torch-scatter==latest+cu101 \
  torch-cluster==latest+cu101 \
  -f https://pytorch-geometric.com/whl/torch-1.5.0.html
"""

from __future__ import unicode_literals, print_function, division
from io import open
import unicodedata
import string
import re
import random
import os.path
from os import path

import torch
import torch.nn as nn
from torch import optim
import torch.nn.functional as F

import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
from datetime import datetime
import time
import math

from torch_geometric.data import Data, DataLoader, InMemoryDataset

class CovidDataSet(InMemoryDataset):
    def __init__(self, root, input_sequence, output_sequence, transform=None, pre_transform=None):
        super(CovidDataSet, self).__init__(root, transform, pre_transform)
        self.data, self.slices = torch.load(self.processed_paths[0])

    @property
    def raw_dir(self):
        return self.root+CLEANED_DATA_DIR

    @property
    def raw_file_names(self):
      mypath = self.raw_dir
      filenames = [f for f in listdir(mypath) if isfile(join(mypath, f))]
      return filenames

    @property
    def processed_file_names(self):
        return ['processed.dt']

    def download(self):
        pass
    
    def process(self):
        
        data_list = []

        for raw_path in self.raw_paths:
          df = pd.read_csv(raw_path)
          for synthetic_seq in df['synthesis_seq'].unique():
            synthetic_data = df[df['synthesis_seq']==synthetic_seq]

            for country in synthetic_data['countryterritoryCode'].unique():
              country_data = synthetic_data[synthetic_data['countryterritoryCode'] == country]
              popData2018 = country_data['popData2018'].values[0]
              _country_code = country_data['_country_code'].values[0]
              
              country_data_i = country_data[:-output_sequence_len]
              country_data_o = country_data[input_sequence_len:]
              
              
              country_data_array = np.array([country_data_i['cases'].to_numpy(),
                                             country_data_i['deaths'].to_numpy(),
                                             country_data_i['popData2018'].to_numpy(),
                                             country_data_i['_country_code'].to_numpy(),
                                             country_data_i['countriesAndTerritories'].to_numpy(),
                                             country_data_i['geoId'].to_numpy(),
                                             country_data_i['countryterritoryCode'].to_numpy(),
                                             country_data_i['continentExp'].to_numpy()
                                             ])
              feature_length = len(country_data_array)
              country_data_array = country_data_array.reshape(feature_length,len(country_data_i))

              country_data_array_y = np.array([country_data_o['cases'].to_numpy(), country_data_o['deaths'].to_numpy()])
              country_data_array_y = country_data_array_y.reshape(2,len(country_data_o))

              x = country_data_array[:feature_length].T
              y = country_data_array_y[:2].T

              sets =0
              x_list = []
              dict_x = dict()
              for i in range(input_sequence_len):
                array_len = ((len(x) -i) - ((len(x)-i)%input_sequence_len))+i
                if array_len <= 0:
                  continue
                sets = int( array_len/ input_sequence_len)
                if sets <= 0:
                  continue
                #print('input seq : ', i , ' ', array_len , ' ',array_len-i , ' number of sets : ', sets)
                x_temp = x[i:array_len].T.reshape(sets,feature_length,input_sequence_len)
                x_temp = x_temp.reshape(feature_length,sets,input_sequence_len)
                uniq_keys = np.array([i+(input_sequence_len*k) for k in range(input_sequence_len)])
                
                arrays_split = np.hsplit(x_temp,sets)
                dict_x.update(dict(zip(uniq_keys, arrays_split)))
              
              dict_y = dict()
              y_list = []
              for i in range(output_sequence_len):
                array_len_y = (len(y)-i) - ((len(y)  - i)%output_sequence_len)+i
                if array_len_y <= 0:
                  continue
                sets = int(array_len_y / output_sequence_len)
                if sets <= 0:
                  continue
                
                #print('output seq : ', i , ' ', array_len_y , ' ',array_len_y-(i) , ' number of sets : ', sets)
                y_temp = y[i:array_len_y].T.reshape(sets, 2, output_sequence_len)
                uniq_keys = np.array([i+(output_sequence_len*k) for k in range(output_sequence_len)])
                y_temp = y_temp.reshape(2,sets,output_sequence_len)
                arrays_split = np.hsplit(y_temp,sets)
                dict_y.update(dict(zip(uniq_keys, arrays_split)))
              

              temp_x_list  = [dict_x[i].T for i in sorted(dict_x.keys())]
              temp_y_list  = [dict_y[i].T for i in sorted(dict_y.keys())]

              #_country_code,popData2018
              xy_list = [Data(x = torch.from_numpy(features).type(torch.FloatTensor).squeeze()) for features in temp_x_list]

              for i in sorted(dict_y.keys()):
                xy_list[i].y = torch.from_numpy(temp_y_list[i]).squeeze()

              data_list += xy_list
          print('processed : '+ raw_path)
        data, slices = self.collate(data_list)
        torch.save((data, slices), self.processed_paths[0])

class EncoderRNN(nn.Module):
    def __init__(self, input_size, parameter_sizes, repeats ,output_size):
        super(EncoderRNN, self).__init__()
        self.input_size = input_size
        self.repeater_input_size = parameter_sizes[0]
        self.hidden_size = parameter_sizes[1]
        self.repeats = repeats
        self.output_size = output_size

        self.fc1 = nn.Linear(input_size, self.repeater_input_size)

        self.layers = dict()

        
        k = 0
        for i in range(repeats):
          i = i+k
          self.layers['fc_'+str(i)] = nn.Linear(self.repeater_input_size, self.hidden_size)
          self.layers['gru_'+str(i+1)] = nn.GRU(self.hidden_size, self.hidden_size)
          self.layers['fc_'+str(i+2)] = nn.Linear(self.hidden_size, self.repeater_input_size)
          k+=2

        self.module_list = nn.ModuleDict(self.layers)

        self.fc2 = nn.Linear(self.repeater_input_size, output_size)
        
    def forward(self, input, hidden):
      output = self.fc1(input)

      k = 0
      for i in range(self.repeats):
        i = i+k
        output = self.layers['fc_'+str(i)](output)
        output, hidden[i-k] = self.layers['gru_'+str(i+1)](output, hidden[i-k])#should be different. check the nlp page
        output = self.layers['fc_'+str(i+2)](output)
        k +=2

      output = self.fc2(output)

      return output, hidden

    def initHidden(self, batch_size):
        return torch.zeros(1, batch_size, self.hidden_size, device=device)

MAX_LENGTH = 20
class AttnDecoderRNN(nn.Module):
  def __init__(self, input_size, parameter_sizes,repeats ,output_size, dropout_p=0.1, max_length=MAX_LENGTH):
    super(AttnDecoderRNN, self).__init__()
    
    self.input_size = input_size
    self.repeater_input_size = parameter_sizes[0]
    self.hidden_size = parameter_sizes[1]
    self.repeats = repeats
    self.output_size = output_size
    self.dropout_p = dropout_p
    self.max_length = max_length

    self.fc1 = nn.Linear(self.input_size, self.hidden_size)
    self.attn = nn.Linear(self.hidden_size * 2, self.max_length)
    self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)
    self.dropout = nn.Dropout(self.dropout_p)

    self.layers = dict()
    k = 0
    for i in range(repeats):
      i = i+k
      self.layers['fc_'+str(i)] = nn.Linear(self.repeater_input_size, self.hidden_size)
      self.layers['gru_'+str(i+1)] = nn.GRU(self.hidden_size, self.hidden_size)
      self.layers['fc_'+str(i+2)] = nn.Linear(self.hidden_size, self.repeater_input_size)
      k+=2

    self.module_list = nn.ModuleDict(self.layers)

    self.out =  nn.Linear(self.repeater_input_size, output_size)
    #nn.Linear(self.hidden_size, self.output_size)

  def forward(self, input,  hidden, encoder_outputs):
    output = self.fc1(input)
    embedded = self.dropout(output)
    
    hidden[0] = hidden[0].squeeze()
    attn_weights = F.softmax(
        self.attn(torch.cat((embedded, hidden[0]), 1)), dim=1) #embedded[0]
    attn_applied = torch.bmm(attn_weights.unsqueeze(0),
                              encoder_outputs.unsqueeze(0))
    
    output = torch.cat((embedded, attn_applied[0]), 1)
    output = self.attn_combine(output).unsqueeze(0)
    hidden[0] = hidden[0].unsqueeze(0)

    k = 0
    for i in range(self.repeats):
      i = i+k
      output = self.layers['fc_'+str(i)](output)
      output, hidden[i-k] = self.layers['gru_'+str(i+1)](output, hidden[i-k])#should be different. check the nlp page
      output = self.layers['fc_'+str(i+2)](output)
      k +=2

    output = self.out(output[0])
    output = F.log_softmax(output, dim=1)

    return output, hidden, attn_weights

  def initHidden(self, batch_size):
    return torch.zeros(1, batch_size, self.hidden_size, device=device)

def get_n_params(model):
    pp=0
    for p in list(model.parameters()):
        nn=1
        for s in list(p.size()):
            nn = nn*s
        pp += nn
    return pp
  

def save_model_parameters(model_parameters_dict, models = None, fileName=None):
  if fileName == None:
    fileName = 'model_parameters_'+str(np.round(np.random.randn(1000,200)[0][0]*1000))

  model_summary = pd.DataFrame(columns =[])
  for i in sorted(model_parameters_dict.keys()):
    param_size = 0
    if models != None:
      param_size = get_n_params(models[i][0])
      param_size += get_n_params(models[i][1])
    row = pd.Series({
                        'model_id':i,
                        'encoder repeats' : model_parameters_dict[i][0]['repeats'],
                        'decoder repeats' : model_parameters_dict[i][1]['repeats'],
                        'parameters' :param_size
    })
    row_df = pd.DataFrame([row], index = [i])
    model_summary = pd.concat([model_summary, row_df])
  model_summary.to_csv(fileName)

#Generate the list of repeat count parameters list
def generate_repeat_counts(alphas , training_dataset_length, enc_repeated_nn_parameters = 132096, dec_repeated_nn_parameters = 132096):
  repeats = []
  for alpha in alphas:
    preferred_parameters  = (1/alpha)* (training_dataset_length / (feature_len+yhat_size))
    for i in range(1,100):
      dec_repeats = i
      enc_repeats = int((preferred_parameters - 
                  (preferred_parameters%enc_repeated_nn_parameters) -
                    (dec_repeated_nn_parameters*dec_repeats)
                  )/ enc_repeated_nn_parameters)
      model_id = 0
      for j in range(1, enc_repeats+1):
        repeats.append((i, j))
  return repeats

def generate_model_parameters(repeat_counts, feature_len, output_len):
  model_dict = dict()
  model_id = 0
  for dec_repeat, enc_repeat in repeat_counts:
    model_dict[model_id] = [{
         'input_size': feature_len,
         'parameter_sizes': [128, 128] ,
         'repeats' : enc_repeat ,
         'output_size' : 128
        },
        {
            'input_size' : 1, 
            'parameter_sizes' : [128, 128],
            'repeats' : dec_repeat ,
            'output_size': output_len,
            'dropout_p' : 0.1, 
        }]
    model_id+=1
  return model_dict

#generate_model_parameters(generate_repeat_counts())

def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):
    torch.save(state, filename)
    if is_best:
        shutil.copyfile(filename, 'model_best.pth.tar')

def save_dict(dictionary, filename):
  np.save(filename, dictionary)

"""Plotting results
----------------

Plotting is done with matplotlib, using the array of loss values
``plot_losses`` saved while training.
"""

import matplotlib.pyplot as plt
plt.switch_backend('agg')
import matplotlib.ticker as ticker
import numpy as np


def showPlot(points, points2):
    plt.figure()
    fig, ax = plt.subplots()
    # this locator puts ticks at regular intervals
    loc = ticker.MultipleLocator(base=0.2)
    ax.yaxis.set_major_locator(loc)
    plt.xlabel('Iteration')
    plt.ylabel('Loss')
    plt.plot(points)
    plt.plot(points2)

def asMinutes(s):
    m = math.floor(s / 60)
    s -= m * 60
    return '%dm %ds' % (m, s)

def timeSince(since, percent):
    now = time.time()
    s = now - since
    es = s / (percent)
    rs = es - s
    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))

"""We can evaluate random sentences from the training set and print out the
input, target, and output to make some subjective quality judgements:
"""

def evaluateRandomly(encoder, decoder, n=10):
    for i in range(n):
        pair = random.choice(pairs)
        print('>', pair[0])
        print('=', pair[1])
        output_words, attentions = evaluate(encoder, decoder, pair[0])
        output_sentence = ' '.join(output_words)
        print('<', output_sentence)
        print('')

def showAttention(input_sentence, output_words, attentions):
    # Set up figure with colorbar
    fig = plt.figure()
    ax = fig.add_subplot(111)
    cax = ax.matshow(attentions.numpy(), cmap='bone')
    fig.colorbar(cax)

    # Set up axes
    ax.set_xticklabels([''] + input_sentence.split(' ') +
                       ['<EOS>'], rotation=90)
    ax.set_yticklabels([''] + output_words)

    # Show label at every tick
    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))
    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))

    plt.show()


def evaluateAndShowAttention(input_sentence):
    output_words, attentions = evaluate(
        encoder1, attn_decoder1, input_sentence)
    print('input =', input_sentence)
    print('output =', ' '.join(output_words))
    showAttention(input_sentence, output_words, attentions)